{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict severity using construct-text similarity on suicide risk lexicon\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "# TODO: !pip install construct-tracker\n",
    "\n",
    "sys.path.append('./../construct-tracker/src/')\n",
    "sys.path.append('./../construct-tracker/src/construct_tracker/')\n",
    "\n",
    "from construct_tracker import lexicon\n",
    "# TODO remove\n",
    "# from importlib import reload\n",
    "# reload(lexicon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl = lexicon.load_lexicon(name = 'srl_v1-0')\n",
    "srl_prototypes = lexicon.load_lexicon(name = 'srl_prototypes_v1-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'local' \n",
    "\n",
    "if location == 'colab':\n",
    "  from google.colab import drive\n",
    "  project_name = 'concept_tracker'\n",
    "  drive.mount('/content/drive')\n",
    "  input_dir = f'/content/drive/MyDrive/datum/{project_name}/data/ctl/'\n",
    "  output_dir = f'/content/drive/MyDrive/datum/{project_name}/data/output/lexicon_paper/'\n",
    "elif location == 'openmind':\n",
    "  input_dir = '/nese/mit/group/sig/projects/dlow/ctl/'\n",
    "  output_dir = '/home/dlow/datum/lexicon/data/output/mpnet/'\n",
    "elif location =='local':\n",
    "  input_dir = './data/input/ctl/'\n",
    "  output_features_dir = './data/input/ctl/'\n",
    "  output_ml_dir = './data/output/ml_performance/cts/'\n",
    "  \n",
    "\n",
    "os.makedirs(output_features_dir, exist_ok=True)\n",
    "os.makedirs(output_ml_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_validation_set = False #False: setting it to True had bad performance). It uses 20% the training set as balanced validation, similar to other models that do 5-fold CV\n",
    "\n",
    "\n",
    "train = pd.read_csv(input_dir+'train10_train_30perc_text_y_balanced_regression.csv', index_col=0)\n",
    "val = pd.read_csv(input_dir+'train10_val_15perc_text_y_regression.csv', index_col=0)\n",
    "test = pd.read_csv(input_dir+'train10_test_15perc_text_y_regression.csv', index_col=0)\n",
    "\n",
    "\n",
    "train = train.dropna()\n",
    "val = val.dropna()\n",
    "test = test.dropna()\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "print(train.shape, val.shape, test.shape)\n",
    "\n",
    "if balanced_validation_set:\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  train, val = train_test_split(train, test_size=0.2, random_state=42)\n",
    "  print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train['y'].value_counts())\n",
    "display(val['y'].value_counts())\n",
    "display(test['y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Count tokens using lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now count whether tokens appear in document:\n",
    "\n",
    "# About 75 sec for 4160 reddits posts\n",
    "# About 76 sec for 5654 CTL convos (just texter) (already lemmatized lexicon)\n",
    "\n",
    "load = True\n",
    "toy = False\n",
    "\n",
    "\n",
    "if load:\n",
    "\t# TODO\n",
    "\tpass\n",
    "\t# counts = pd.read_csv(save_dir+'suicide_risk_lexicon_counts.csv')\n",
    "\t# counts['subreddit'] = reddit_df_mini['subreddit'].values\n",
    "\t# with open(save_dir+'suicide_risk_lexicon_matches_construct2doc.json', 'r') as json_file:\n",
    "\t# \tmatches_construct2doc  = json.load(json_file)\n",
    "\n",
    "\t# # Can do the same for matches_by_construct, matches_doc2construct\n",
    "else:\n",
    "\tfor split, filename in [\n",
    "\t\t\t(train, 'train10_train_30perc_text_y_balanced_regression'),\n",
    "\t\t\t(test, 'train10_test_15perc_text_y_regression')\n",
    "\t\t\t]:\n",
    "\t\t\n",
    "\t\tsplit['text'] = split['text'].str.replace('\\r', '')\n",
    "\t\tdocuments = [n.replace('\\r', '') for n in documents]\n",
    "\t\tif toy:\n",
    "\t\t\t# documents = train['text'].sample(20).values\n",
    "\t\t\tdocuments = split['text'].iloc[:40]\n",
    "\t\t\tsplit = split.iloc[:40]\n",
    "\t\telse:\n",
    "\t\t\tdocuments = split['text'].values\n",
    "\n",
    "\n",
    "\t\t# srl = lexicon.lemmatize_tokens(srl)\n",
    "\t\tcounts, matches_by_construct, matches_doc2construct, matches_construct2doc  = srl.extract(documents,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdocuments_df = split,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnormalize = False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsave_dir = output_features_dir,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsave_append_to_filename = filename\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n",
    "\t\t# counts['subreddit'] = reddit_df_mini['subreddit'].values\n",
    "\t\tdisplay(counts)\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_features_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Interpret counts: visualize matches in context  \n",
    "\n",
    "\n",
    "# n = 2\n",
    "# highlight_constructs = ['Lethal means for suicide', 'Passive suicidal ideation', 'Direct self-injury', 'Panic', 'Depressed mood']\n",
    "# for construct in highlight_constructs:\n",
    "# \tprint(f'Matches for {construct}:')\n",
    "# \tlexicon.highlight_matches(documents, construct,n, matches_construct2doc, random_seed=42)\n",
    "# \tprint()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Construct-Text Similarity (CTS)\n",
    "Find similar tokens to the tokens in the lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the highest prototypes for CTS (3/3 by raters) `srl_prototypes` so that it doesn't find similarity with low prototypical tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do not save doc embeddings, to heavy. Do sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from construct_tracker import cts\n",
    "from importlib import reload\n",
    "reload(cts)\n",
    "\n",
    "# ~5000k CTL convos for 50 constructs - 60m\n",
    "# 56 min for 50 constructs, chat without responder, all-MiniLM-L6-v2, preloading lexicon tokens, with lemmatization\n",
    "# Encoding document clause tokens is what takes the longest.\n",
    "# computing similarity between 50 constructs and 5353 documents...#  06:50\n",
    "\n",
    "load = False\n",
    "toy = False\n",
    "\n",
    "if load:\n",
    "\tX_train_df = pd.read_csv(output_features_dir+'cts-scores_count-sum_thresh-03_train10_test_15perc_text_y_regression_24-08-14T22-50-58/cts_scores.csv')\n",
    "\tX_test_df = pd.read_csv(output_features_dir+'cts-scores_count-sum_thresh-03_24-08-14T16-48-28/train10_train_30perc_text_y_balanced_regression_cts-scores.csv')\n",
    "\n",
    "else:\n",
    "\tfor split, filename in [\n",
    "\t\t(train, 'train10_train_30perc_text_y_balanced_regression'),\n",
    "\t\t(test, 'train10_test_15perc_text_y_regression')\n",
    "\t\t]:\n",
    "\t\tif toy:\n",
    "\t\t\tdocuments = split['text'].iloc[:5].values\n",
    "\t\t\tsplit = split.iloc[:5]\n",
    "\t\telse:\n",
    "\t\t\tdocuments = split['text'].values\n",
    "\t\t# 31 sec for 42 reddit posts (relatively short) and 50 constructs. \n",
    "\t\tlexicon_dict = srl_prototypes.to_dict()\n",
    "\t\tfeatures, lexicon_dict_final_order, cosine_similarities = cts.measure(\n",
    "\t\t\tlexicon_dict,\n",
    "\t\t\tdocuments,\n",
    "\t\t\tdocuments_df = split, # pass the DF so it can concat\n",
    "\t\t\t# You can store and reload embeddings for lexicon tokens\n",
    "\t\t\t# stored_embeddings_path = './data/input/lexicons/embeddings_lexicon-tokens_all-mpnet-base-v2.pickle',\n",
    "\t\t\tdocument_representation = 'sentence',\n",
    "\t\t\tcount_if_exact_match = False,\n",
    "\t\t\tembeddings_model = \"avsolatorio/GIST-small-Embedding-v0\",\n",
    "\t\t\tsimilarity_threshold = 0, \n",
    "\t\t\tsave_dir = output_features_dir,\n",
    "\t\t\tsave_doc_embeddings = False,\n",
    "\t\t\t# document_embeddings_path = output_features_dir+'/embeddings_',\n",
    "\t\t\tsave_append_to_filename = filename,\n",
    "\t\t\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# features2 = pd.concat([split, features], axis=1)\n",
    "# features2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features2.to_csv(output_features_dir+'cts-scores_count-sum_thresh-03_train10_test_15perc_text_y_regression_24-08-14T22-50-58/cts_scores2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_constructs_max = ['Passive suicidal ideation_max',\n",
    " 'Active suicidal ideation & suicidal planning_max',\n",
    " 'Lethal means for suicide_max',\n",
    " 'Direct self-injury_max',\n",
    " 'Suicide exposure_max',\n",
    " 'Other suicidal language_max','Depressed mood_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of counts split by subreddit\n",
    "features2[highlight_constructs_max+['y']].groupby('y').sum().plot.bar()\n",
    "plt.ylabel(f'Sum of cosine similarities > {threshold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating the new dataframe based on the conditions\n",
    "# result = counts[highlight_constructs].where(counts[highlight_constructs] >= 1, features_threshold)\n",
    "# result['subreddit']=subreddits\n",
    "\n",
    "\n",
    "# # Bar plot of counts split by subreddit\n",
    "# result[highlight_constructs+['subreddit']].groupby('subreddit').sum().plot.bar()\n",
    "# plt.ylabel(f'Sum of cosine similarities')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If below threshold then replace with NaN\n",
    "# threshold = 0.45 # depends on embeddings used\n",
    "\n",
    "# features_threshold = result[highlight_constructs]\n",
    "# features_threshold[features_threshold <= threshold] = np.nan\n",
    "# features_threshold['subreddit'] = subreddits\n",
    "\n",
    "# features_threshold[highlight_constructs+['subreddit']].groupby('subreddit').sum().plot.bar()\n",
    "# plt.ylabel(f'Sum of cosine similarities > {threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If below threshold then replace with NaN\n",
    "# threshold = 0.70 # depends on embeddings used\n",
    "# features_threshold = result[highlight_constructs_max]\n",
    "# features_threshold[features_threshold <= threshold] = np.nan\n",
    "# features_threshold['subreddit'] = subreddits\n",
    "\n",
    "# features_threshold[highlight_constructs_max+['subreddit']].groupby('subreddit').sum().plot.bar()\n",
    "# plt.ylabel(f'Sum of cosine similarities > {threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tokenization messing up space, which doesnt allow highlithing matches in context\n",
    "# TODO: highlight exact match if possible: replace values in cosine_similarities\n",
    "# Interpret scores\n",
    "doc_id = 10\n",
    "\n",
    "# Interpret counts: visualize matches in context  \n",
    "\n",
    "highlight_constructs = ['Lethal means for suicide', 'Passive suicidal ideation', 'Direct self-injury', 'Panic', 'Depressed mood']\n",
    "for construct in highlight_constructs:\n",
    "\tprint(f'Matches for {construct}:')\n",
    "\t\n",
    "\tmost_similar_lexicon_token, most_similar_document_token, highest_similarity = cts.get_highest_similarity_phrase(doc_id, construct, documents, features['documents_tokenized'].tolist(), cosine_similarities, lexicon_dict_final_order)\n",
    "\tprint()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concept_tracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
